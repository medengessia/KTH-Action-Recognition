{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as opt\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from models.model_saver import SaveBestModel\n",
    "from models.kth_set_splitter import KTHDataset\n",
    "from models.cnn_3d import CNNModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download KTH video dataset to isolate the .txt file containing the split for Training, Validation and Test sets\n",
    "with open('subjects.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for line in lines:\n",
    "    dataset, subjects = line.split(':\\t\\t')\n",
    "    datasets[dataset] = subjects[:-1]\n",
    "\n",
    "seq_length = 75\n",
    "image_shape = 120\n",
    "\n",
    "# Download KTH video dataset to isolate the .txt file containing sequences configuration\n",
    "annot_files = 'sequences00.txt'\n",
    "video_dir = 'actions'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(120, scale=(0.8, 1.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "data_train = KTHDataset(annotations_file=annot_files,\n",
    "                            data_dir=video_dir,\n",
    "                            subjects=datasets['Training'],\n",
    "                            seq_length=seq_length,\n",
    "                            image_shape=image_shape)\n",
    "\n",
    "data_valid = KTHDataset(annotations_file=annot_files, \n",
    "                            data_dir=video_dir,\n",
    "                            subjects=datasets['Validation'], \n",
    "                            seq_length=seq_length, \n",
    "                            image_shape=image_shape)\n",
    "\n",
    "data_test = KTHDataset(annotations_file=annot_files, \n",
    "                           data_dir=video_dir,\n",
    "                           subjects=datasets['Test'], \n",
    "                           seq_length=seq_length,\n",
    "                           image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters definition\n",
    "\n",
    "batch_size = 2\n",
    "channels = 3\n",
    "num_classes = 6\n",
    "num_epochs = 50\n",
    "\n",
    "train_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=data_valid, batch_size=batch_size, shuffle=False, num_workers=3, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train_epoch(epoch, num_epochs, model, optimizer, dataloader, criterion):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    for sequence, label in progress:\n",
    "        sequence = sequence.permute(0,2,1,3,4)  # Adjust the shape so that the number of channels gets the right position\n",
    "        sequence = sequence.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Zero the gradients for every batch !\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        pred_label = model(sequence)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        train_loss = criterion(pred_label, label)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        total_loss += train_loss.item()\n",
    "        progress.set_description(f'[%.2g/%.2g] train loss. %.2f' % (epoch+1, num_epochs, total_loss/len(sequence)))\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion):\n",
    "    \n",
    "    acc = 0.0\n",
    "    n = 0\n",
    "    pred_labels, true_labels = [], []\n",
    "    total_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "        for sequence, label in progress:\n",
    "            sequence = sequence.permute(0,2,1,3,4) # Adjust the shape so that the number of channels gets the right position\n",
    "            sequence = sequence.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            true_labels.extend(list(label.detach().cpu().numpy()))\n",
    "            pred_label = model(sequence)\n",
    "\n",
    "            valid_loss = criterion(pred_label, label)\n",
    "            pred_label = pred_label.argmax(dim=1)\n",
    "\n",
    "            vec_label = label.flatten()\n",
    "            acc += (pred_label == vec_label).sum().item()\n",
    "            n += len(vec_label)\n",
    "            total_loss += valid_loss.item()\n",
    "\n",
    "            pred_labels.extend(list(pred_label.detach().cpu().numpy()))\n",
    "            accuracy = (acc / n)*100\n",
    "\n",
    "            desc = '[VALID]> loss. %.2f > acc. %.2g%%' % (total_loss/len(label), accuracy)\n",
    "            progress.set_description(desc)\n",
    "\n",
    "    return total_loss, true_labels, pred_labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "    \n",
    "acc = 0\n",
    "results = []\n",
    "best_loss_val = float('inf')\n",
    "saver = SaveBestModel(best_valid_loss=best_loss_val)\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "model = CNNModel(in_dim=channels, num_classes=num_classes)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "adam = opt.Adagrad(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(epoch, num_epochs=num_epochs, model=model, optimizer=adam, dataloader=train_loader, criterion=cross_entropy)\n",
    "    valid_loss, true_labels, pred_labels, accuracy = validate_epoch(model=model, dataloader=valid_loader, criterion=cross_entropy)\n",
    "\n",
    "    if acc < accuracy:\n",
    "        results.append((true_labels, pred_labels))\n",
    "        acc = accuracy\n",
    "\n",
    "    if valid_loss < best_loss_val:\n",
    "        best_loss_val = valid_loss\n",
    "        saver.save(current_valid_loss=best_loss_val, epoch=epoch, model=model, optimizer=adam, criterion=cross_entropy)\n",
    "        ## save the checkpoints\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(results[-1][0], results[-1][1], normalize='true')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(conf_mat, ax=ax, square=True, annot=True)\n",
    "ax.xaxis.set_ticklabels(['boxing', 'clap', 'waving', 'jogging', 'running', 'walking'])   \n",
    "ax.yaxis.set_ticklabels(['boxing', 'clap', 'waving', 'jogging', 'running', 'walking'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
